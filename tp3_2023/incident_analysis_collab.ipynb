{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "nlu_jointbert_dl21.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d895ee3c2f24cf093ed8e324d8a0906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb52cc7134984a82bbe2c4956b8b2496",
              "IPY_MODEL_e59d3991235d49da9435f3d56c2fd4ed",
              "IPY_MODEL_7357b9d5f69e4127811ca68a8932d96b"
            ],
            "layout": "IPY_MODEL_0454fdc8314d43a09c8fe4928993139a"
          }
        },
        "eb52cc7134984a82bbe2c4956b8b2496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84aa96d9f4b84755a7881a1a5e73117d",
            "placeholder": "​",
            "style": "IPY_MODEL_1a07031b0cff47abb9c5aad9ada11eed",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e59d3991235d49da9435f3d56c2fd4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9799f2695b4c4b489df41184c7320d76",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c89a80f0ff4842fca703df8f4db9b16f",
            "value": 1618
          }
        },
        "7357b9d5f69e4127811ca68a8932d96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3867796c37d48109ec500527df5418a",
            "placeholder": "​",
            "style": "IPY_MODEL_649f96a1cd364ee9bd07d0b2ddff725f",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 97.5kB/s]"
          }
        },
        "0454fdc8314d43a09c8fe4928993139a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84aa96d9f4b84755a7881a1a5e73117d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a07031b0cff47abb9c5aad9ada11eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9799f2695b4c4b489df41184c7320d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89a80f0ff4842fca703df8f4db9b16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3867796c37d48109ec500527df5418a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649f96a1cd364ee9bd07d0b2ddff725f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed893a4c1733449eb0e3c3fdc0dad3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd31507af0a641639da8c303b1137575",
              "IPY_MODEL_a007799b05234a4d87562f96ac68f0b9",
              "IPY_MODEL_f03b677ec46240af9e7eb3c46db805fb"
            ],
            "layout": "IPY_MODEL_2b831ecdf281410b8045c41ca73e2283"
          }
        },
        "cd31507af0a641639da8c303b1137575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2266674c45d942329e9f3456c2a85f4b",
            "placeholder": "​",
            "style": "IPY_MODEL_44478ec9d27444aaa2906f898a3b64e5",
            "value": "tokenizer.model: 100%"
          }
        },
        "a007799b05234a4d87562f96ac68f0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c37c2e5f33472c98b4f39df28341a2",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c88e144ea914859a192dfe2c1539b0d",
            "value": 499723
          }
        },
        "f03b677ec46240af9e7eb3c46db805fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_636bd35486bc4906881bf1776283e2e8",
            "placeholder": "​",
            "style": "IPY_MODEL_983f4746819b4caaa85f64429d0b7c10",
            "value": " 500k/500k [00:00&lt;00:00, 16.9MB/s]"
          }
        },
        "2b831ecdf281410b8045c41ca73e2283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2266674c45d942329e9f3456c2a85f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44478ec9d27444aaa2906f898a3b64e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41c37c2e5f33472c98b4f39df28341a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c88e144ea914859a192dfe2c1539b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "636bd35486bc4906881bf1776283e2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "983f4746819b4caaa85f64429d0b7c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77494927d0074f97af78ad776cd06bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6005517db33438d9ee6d9459c42e48b",
              "IPY_MODEL_46ed8682c81d4d829581086ccaa6c82b",
              "IPY_MODEL_e5bcd20650524552a211eae0f4f9bf4c"
            ],
            "layout": "IPY_MODEL_64a48eebf45d480191115426ddfbab7b"
          }
        },
        "b6005517db33438d9ee6d9459c42e48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee3a5cee13245259b35a1d2914ed4c8",
            "placeholder": "​",
            "style": "IPY_MODEL_37df1f4cc20848c1b5405075c7fe1cba",
            "value": "tokenizer.json: 100%"
          }
        },
        "46ed8682c81d4d829581086ccaa6c82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb61438f15194325878f42babd7278e2",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cfdc8235aca4ba9898dd5d55363c18c",
            "value": 1842767
          }
        },
        "e5bcd20650524552a211eae0f4f9bf4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc8cfe1b42f748a78254e56d7d3434c2",
            "placeholder": "​",
            "style": "IPY_MODEL_694f871c818843aca5b180fc0265a56c",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 4.54MB/s]"
          }
        },
        "64a48eebf45d480191115426ddfbab7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ee3a5cee13245259b35a1d2914ed4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37df1f4cc20848c1b5405075c7fe1cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb61438f15194325878f42babd7278e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cfdc8235aca4ba9898dd5d55363c18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc8cfe1b42f748a78254e56d7d3434c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694f871c818843aca5b180fc0265a56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0891b952744a9b97819b45ea0374ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e118eb0a973e4f1aa1c3766944a754ec",
              "IPY_MODEL_4f03a93e3fa446159dda4ac863bc87f3",
              "IPY_MODEL_96f564ea5b0c4e6bb144645e7decc5a5"
            ],
            "layout": "IPY_MODEL_6119f5f4d22f4095b00e31937d45f3b5"
          }
        },
        "e118eb0a973e4f1aa1c3766944a754ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d1e67ac2f245e1b7fd213e4ba7fbb2",
            "placeholder": "​",
            "style": "IPY_MODEL_10b84e76b0aa4a7aa999c31b176414c3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4f03a93e3fa446159dda4ac863bc87f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c734f081e9ab472b9fd1caa8d6f60caa",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1551553bde5840f39eba4168785a0305",
            "value": 414
          }
        },
        "96f564ea5b0c4e6bb144645e7decc5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_656e046ec8c34af4b286333a22879da3",
            "placeholder": "​",
            "style": "IPY_MODEL_5e2178758b3347969d32f98b9758e087",
            "value": " 414/414 [00:00&lt;00:00, 33.6kB/s]"
          }
        },
        "6119f5f4d22f4095b00e31937d45f3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d1e67ac2f245e1b7fd213e4ba7fbb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b84e76b0aa4a7aa999c31b176414c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c734f081e9ab472b9fd1caa8d6f60caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1551553bde5840f39eba4168785a0305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "656e046ec8c34af4b286333a22879da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e2178758b3347969d32f98b9758e087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e724ce593e2492abff6df0f6d81248c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0ee3364041d4495b0afd3e3a7757cb8",
              "IPY_MODEL_6d28116701b54c3d94a170eb8f639747",
              "IPY_MODEL_8d8240d71cc1418bbaa8c88fa0f5ccd1"
            ],
            "layout": "IPY_MODEL_25767f593cb0494592d07bd83872ba41"
          }
        },
        "e0ee3364041d4495b0afd3e3a7757cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2629265df0b84e77b16533412e6e0315",
            "placeholder": "​",
            "style": "IPY_MODEL_72c7e4bf55a14bdc81462486db503f06",
            "value": "config.json: 100%"
          }
        },
        "6d28116701b54c3d94a170eb8f639747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8528cf1d5d7c472fb1e0ff92608b910b",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3608d87e95449cb908abe1a36ae6c30",
            "value": 614
          }
        },
        "8d8240d71cc1418bbaa8c88fa0f5ccd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfdeeaf4c4d4467091b88efd0ad316f9",
            "placeholder": "​",
            "style": "IPY_MODEL_a8a92504bf714e7f9bb4d80802e2ac85",
            "value": " 614/614 [00:00&lt;00:00, 47.1kB/s]"
          }
        },
        "25767f593cb0494592d07bd83872ba41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2629265df0b84e77b16533412e6e0315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c7e4bf55a14bdc81462486db503f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8528cf1d5d7c472fb1e0ff92608b910b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3608d87e95449cb908abe1a36ae6c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfdeeaf4c4d4467091b88efd0ad316f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a92504bf714e7f9bb4d80802e2ac85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjRqJ7sS5vsQ"
      },
      "source": [
        "## Install transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OO2HRXgV5HA",
        "outputId": "75ec9d03-6d27-4903-ef59-2c42bdd51897"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbLDTz7m5_rs"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connection à drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "v7MXPT0AnVx1",
        "outputId": "97c2492c-f7dd-4aff-f38e-af470589f3d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/ULaval/dev_examples.json'\n",
        "new_exemples_path = '/content/drive/MyDrive/ULaval/new_examples.json'\n",
        "test_data_path = '/content/drive/MyDrive/ULaval/test_examples.json'\n",
        "\n",
        "\n",
        "def load_incident_dataset(filename):\n",
        "    with open(filename, 'r') as fp:\n",
        "        incident_list = json.load(fp)\n",
        "\n",
        "    return incident_list\n",
        "\n",
        "# Load datasets\n",
        "train_data = load_incident_dataset(train_data_path)\n",
        "new_examples = load_incident_dataset(new_exemples_path)\n",
        "test_data_path = load_incident_dataset(test_data_path)"
      ],
      "metadata": {
        "id": "1aSV641hnj5m"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgnD-4G3VT84",
        "outputId": "9aacdc2d-cfae-4ddc-d52f-322bc990ae6b"
      },
      "source": [
        "# train_data += new_examples\n",
        "\n",
        "example = train_data[10]\n",
        "example"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ' On August 24  2003  Jose Crespin Company  a stucco contractor  employed  Employee #1 and four coworkers. They were applying a stucco finish to the  exterior insulating finishing system on the Home Depot  Store Number 6555.  After completing the lumber canopy at the west end of the building  the  employees moved to the east end to finish the exterior insulating finishing  system on the spandrel panels at the garden center. While waiting for the  building surface to cool  the employees took a work break. During their break   the weather swiftly changed from clear and sunny to heavy rain and strong  winds. The employees then moved to the north side of the building at the  garden center where they hoped that the masonry piers and spandrel panels  would shelter them from the rain. The wind reached speeds in excess of 40 mph  and began collapsing the masonry piers (C.1-0.2 and C.1-0.3) where the  employees were standing. Realizing the imminent danger of the collapsing  piers  four employees fled from the area. Employee #1 became entangled in a  sheet of plastic  and was unable to break free when stub pier \"C.1-0.3\"  a  14-foot tall masonry pier  collapsed on him  crushing him. He was killed from  asphyxia.                                                                       ',\n",
              " 'arguments': {'EVENT': ['14-foot tall masonry pier  collapsed on him  crushing him',\n",
              "   'asphyxia'],\n",
              "  'ACTIVITY': ['applying a stucco finish to the  exterior insulating finishing system',\n",
              "   'moved to the north side of the building at the  garden center where they hoped that the masonry piers and spandrel panels  would shelter them from the rain'],\n",
              "  'WHO': ['Employee #1', 'Employee #1 and four coworkers'],\n",
              "  'WHERE': ['the garden center', 'Home Depot  Store Number 6555'],\n",
              "  'WHEN': ['August 24  2003'],\n",
              "  'CAUSE': ['The wind reached speeds in excess of 40 mph  and began collapsing the masonry piers',\n",
              "   'a  14-foot tall masonry pier  collapsed on him  crushing him',\n",
              "   'was unable to break free'],\n",
              "  'EQUIPMENT': ['exterior insulating finishing system',\n",
              "   'masonry piers',\n",
              "   'spandrel panels'],\n",
              "  'INJURY': ['asphyxia'],\n",
              "  'INJURED': ['Employee #1'],\n",
              "  'BODY-PARTS': [''],\n",
              "  'DEATH': ['Employee #1']}}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_VahZ-O7JXU"
      },
      "source": [
        "## Load Tokenizer from transformers\n",
        "\n",
        "We will use a pretrained bert model `bert-base-cased` for both Tokenizer and our classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA8sh4pLVT84"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQFs80Rg7jj4"
      },
      "source": [
        "# Encode texts from the dataset\n",
        "\n",
        "We have to encode the texts using the tokenizer to create tensors for training the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpUnhqA2VT84",
        "outputId": "138bad40-f35f-4e9d-c9ef-7cea4fbd0a5a"
      },
      "source": [
        "# https://huggingface.co/transformers/preprocessing.html\n",
        "\n",
        "def encode_texts(tokenizer, texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "\n",
        "texts = [d[\"text\"] for d in train_data]\n",
        "tds = encode_texts(tokenizer, texts)\n",
        "tds.keys()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjaIbB7vVT84"
      },
      "source": [
        "encoded_texts = tds\n",
        "\n",
        "for t in encoded_texts[\"input_ids\"]:\n",
        "  if t.shape != (512,):\n",
        "    print(t.shape)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8iBMHa577iQ"
      },
      "source": [
        "## Encode labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j0i00AW8gjA"
      },
      "source": [
        "### Slots\n",
        "\n",
        "To padd all the texts to the same length, the tokenizer will use special characters. To handle those we need to add <PAD> to slots_names. It can be some other symbol as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNW91LSgVT84",
        "outputId": "a07f88ef-ae3b-482f-f444-e4e73586ceed"
      },
      "source": [
        "# encode slots\n",
        "slot_names = set()\n",
        "for td in train_data:\n",
        "    slots = td[\"arguments\"]\n",
        "    for slot in slots:\n",
        "        slot_names.add(slot)\n",
        "\n",
        "        # slot_names.add(\"B-\" + slot)\n",
        "        # slot_names.add(\"I-\" + slot)\n",
        "slot_names = list(slot_names)\n",
        "slot_names.insert(0, \"<PAD>\")\n",
        "print(len(slot_names))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fv7aVEoVT84",
        "outputId": "f4229092-cc4a-496f-b684-964bdeded5a5"
      },
      "source": [
        "slot_map = dict() # slot -> index\n",
        "for idx, us in enumerate(slot_names):\n",
        "    slot_map[us] = idx\n",
        "slot_map"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<PAD>': 0,\n",
              " 'SUBSTANCE': 1,\n",
              " 'INJURY': 2,\n",
              " 'INJURED': 3,\n",
              " 'WHERE': 4,\n",
              " 'ACTIVITY': 5,\n",
              " 'EQUIPMENT': 6,\n",
              " 'CAUSE': 7,\n",
              " 'BODY-PARTS': 8,\n",
              " 'EVENT': 9,\n",
              " 'WHEN': 10,\n",
              " 'DEATH': 11,\n",
              " 'WHO': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62lsuEZoVT84",
        "outputId": "603d0be1-9876-460f-dec5-aa75c76e209e"
      },
      "source": [
        "# gets slot name from its values\n",
        "def get_slot_from_word(word, slot_dict):\n",
        "    for slot_label, value in slot_dict.items():\n",
        "        for slot_element in value:\n",
        "          if word in slot_element.split():\n",
        "              index = slot_element.index(word)\n",
        "              return slot_label\n",
        "              # return \"B-\" + slot_label if index == 0 else \"I-\" + slot_label\n",
        "    return None\n",
        "\n",
        "print(train_data[0][\"text\"])\n",
        "print(train_data[0][\"arguments\"])\n",
        "print(\"slot_name for grind is : \", get_slot_from_word(\"grind\", train_data[0][\"arguments\"]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " At around 10:00 p.m. on November 10  2013  Employee #1  with Villager  Construction Inc.  with a coworker  were using an asphalt milling machine  (Wirtgen; Model Number: W2100) to grind out existing asphalt from an  interstate at a railroad bridge overpass. Employee # 1 was standing on the  ground  checking the depth of the cut into the asphalt  using a handheld  pendant attached to the machine. The pedant could stretch out from ten to 15  ft. This allowed Employee #1 to walk back and forth  checking the cut. The  operator was on the top of the milling machine  controlling the operation of  the machine and ensuring that the milling machine and dump truck (driven by a  second coworker  who worked for an independent trucking service) kept a safe  working distance. A different company  Protective Services Inc. (PSI)  was  responsible for the traffic control of the job site and had shut down the  inside lane of a three lane section of the interstate  so that work could be  conducted on that lane. The entire work zone was approximately two miles long   from start to finish. Employee #1 and the operator of the milling machine had  completed milling four sections (eight total passes) of the inside lane at the  bridge overpasses and were waiting for PSI to shut down the center lane. Dual  lane shut down of the inside and center lanes of the interstate was completed  around 9:30 p.m.  and Employee #1 and the milling machine operator milled two  sections (four total passes) of the center lane. Once both sides of the  overpass were milled out  approximately 200 ft on each side  Employee #1 and  the operator of the milling machine moved the milling machine down the  interstate  approximately1 000 ft  to a railroad overpass and began setting up  to mill the center lane sections. The truck driver backed his truck into  position and remained in the truck to move the truck slowly forward as milling  took place. Employee #1 was positioned between the milling machine and the  concrete median dividers  inside the coned off work zone. The lanes of travel  were approximately 12 ft wide  so the milling machine made two passes  since  it can only cut seven ft wide on each section to cover the entire lane.  Employee #1 was standing approximately three ft in the far inside lane on the  ground between milling machine and interior median wall inside of the approved  traffic control set up  and approximately midway up the machine and 17 ft from  the traffic control devices and flow of traffic. The milling machine was  approximately nine ft wide by 50 ft long  while operating. Employee #1 was  guarded by the machine from the flow of traffic. Approximately five to ten  minutes into the first pass  the milling machine operator noticed lights  hitting the reflectors on the inside wall and turned briefly to see a vehicle  coming. The operator thought it was the Project manager coming to check on the  status of the project. Then  the operator realized that the oncoming vehicle  was not equipped with a strobe  as required in work zones. The operator turned  and yelled for Employee # 1 to run for safety  as a Chevrolet Tahoe came down  the inside lane where Employee #1 was standing. The driver of the Tahoe  continued traveling in the far inside lane of the work zone  where Employee #1  was struck and thrown some 100 ft from where he was originally standing. The  vehicle was moving approximately 45 mph per hour. As he was transferred to a  hospital by emergency personnel  Employee #1 was treated for severe trauma   lacerations  fractures  and contusions to the body and head. Employee #1 was  pronounced dead at the hospital. The driver of the vehicle disregarded the  traffic control set up  all warning lights on the rear of the milling machine   and cone spacing of 100 ft. The construction work zone was set up correctly  with all signage  cone spacing  tapering  attenuators  and lighting; all of  the traffic control set up was approved by MUTCD for this type of tr \n",
            "{'EVENT': ['Employee #1  was struck and thrown'], 'ACTIVITY': ['checking the depth of the cut into the asphalt', 'grind out existing asphalt from an  interstate at a railroad bridge overpass'], 'WHO': ['Employee #1', 'Employee #1  with Villager  Construction Inc.'], 'WHERE': ['railroad bridge overpass'], 'WHEN': ['November 10  2013'], 'CAUSE': ['The driver of the Tahoe  continued traveling in the far inside lane of the work zone'], 'EQUIPMENT': ['asphalt milling machine', 'Wirtgen; Model Number: W2100', 'handheld  pendant', 'a Chevrolet Tahoe'], 'INJURY': ['severe trauma   lacerations  fractures  and contusions'], 'INJURED': ['Employee #1'], 'BODY-PARTS': ['body and head'], 'DEATH': ['Employee #1']}\n",
            "slot_name for grind is :  ACTIVITY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "NiyymulXyxY6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VUnAC8-VT84"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# find the max encoded test length\n",
        "# tokenizer pads all texts to same length anyway so\n",
        "# just get the length of the first one's input_ids\n",
        "max_len = len(encoded_texts[\"input_ids\"][0])\n",
        "\n",
        "def encode_slots(all_slots, all_texts, tokenizer, slot_map, max_len=512):\n",
        "    encoded_slots = np.zeros(shape=(len(all_texts), max_len), dtype=np.int32)\n",
        "\n",
        "    for idx, text in enumerate(all_texts):\n",
        "        enc = [] # for this idx, to be added at the end to encoded_slots\n",
        "        bert_token_count = 0  # Track the number of BERT tokens\n",
        "\n",
        "        raw_tokens = text.split()\n",
        "        for rt in raw_tokens:\n",
        "            bert_tokens = tokenizer.tokenize(rt)\n",
        "            bert_token_count += len(bert_tokens)\n",
        "\n",
        "            if bert_token_count > max_len - 2:  # Account for [CLS] and [SEP]\n",
        "                break  # Stop processing if max length is reached\n",
        "\n",
        "            rt_slot_name = get_slot_from_word(rt, all_slots[idx])\n",
        "            if rt_slot_name is not None:\n",
        "                enc.extend([slot_map[rt_slot_name]] * len(bert_tokens))\n",
        "            else:\n",
        "                enc.extend([0] * len(bert_tokens))\n",
        "\n",
        "        # Truncate or pad the enc to fit into encoded_slots\n",
        "        enc = enc[:max_len - 2]  # Truncate if necessary\n",
        "        enc_length = len(enc)\n",
        "        if enc_length < max_len - 2:\n",
        "            enc.extend([0] * (max_len - 2 - enc_length))  # Pad with zeros if shorter\n",
        "\n",
        "        encoded_slots[idx, 1:len(enc) + 1] = enc\n",
        "\n",
        "    return torch.tensor(encoded_slots)\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Hj-St4VT84",
        "outputId": "6caef501-b0df-4bd1-ca78-edc5ef7f6a25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "all_slots = [td[\"arguments\"] for td in train_data]\n",
        "all_texts = [td[\"text\"] for td in train_data]\n",
        "\n",
        "print(len(all_slots))\n",
        "print(len(all_texts))\n",
        "print(slot_map)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "100\n",
            "{'<PAD>': 0, 'SUBSTANCE': 1, 'INJURY': 2, 'INJURED': 3, 'WHERE': 4, 'ACTIVITY': 5, 'EQUIPMENT': 6, 'CAUSE': 7, 'BODY-PARTS': 8, 'EVENT': 9, 'WHEN': 10, 'DEATH': 11, 'WHO': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIEsMzT8VT84"
      },
      "source": [
        "encoded_slots = encode_slots(all_slots, all_texts, tokenizer, slot_map)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw9aA2_gVT84",
        "outputId": "40b17d8b-27ae-41c9-ec45-747078c58e23"
      },
      "source": [
        "encoded_slots[0]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10,  9,  9,  9,  9,\n",
              "         9,  9, 12, 12, 12, 12, 12, 12, 12,  5,  0,  0,  0,  0,  0,  5,  5,  6,\n",
              "         6,  0,  0,  0,  0,  0,  6,  6,  6,  0,  0,  0,  0,  0,  5,  5,  5,  5,\n",
              "         5,  5,  5,  5,  5,  5,  5,  5,  0,  0,  0,  9,  9,  9,  9,  0,  0,  9,\n",
              "         0,  0,  5,  0,  5,  5,  5,  5,  5,  5,  5,  5,  5,  0,  5,  6,  6,  6,\n",
              "         0,  0,  5,  0,  0,  7,  0,  0,  0,  0,  0,  5,  5,  0,  0,  0,  0,  0,\n",
              "         0,  0,  9,  9,  9,  9,  9,  9,  0,  0,  0,  9,  0,  5,  5,  0,  0,  7,\n",
              "         0,  9,  0,  5,  0,  5,  5,  6,  6,  0,  5,  0,  5,  5,  6,  9,  0,  0,\n",
              "         5,  6,  6,  9,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  5,\n",
              "         0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        12, 12,  0,  0,  0,  0,  9,  0,  0,  5,  0,  0,  5,  5,  0,  0,  9,  0,\n",
              "         0,  0,  5,  7,  7,  5,  5,  0,  7,  0,  5,  5,  5,  0,  0,  7,  0,  0,\n",
              "         0,  0,  0,  0,  0,  7,  0,  7,  7,  9,  0,  0,  0,  0,  5,  0,  0,  0,\n",
              "         0,  9,  9,  9,  9,  9,  9,  9,  5,  0,  5,  5,  6,  6,  0,  0,  6,  0,\n",
              "         0,  0,  0,  0,  0,  0,  5,  5,  7,  7,  5,  5,  5,  0,  0,  0,  9,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  7,  0,  0,  5,  5,  7,\n",
              "         9,  0,  0,  5,  5,  5,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9,  9,\n",
              "         9,  9,  9,  9,  9,  9,  5,  6,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  5,  5,  0,  0,  0,  0,  0,  0,  5,  5,  5,  5,  0,  0,  0,  5,  0,\n",
              "         0,  0,  0,  0,  0,  9,  9,  9,  9,  9,  9,  9,  5,  0,  5,  5,  6,  6,\n",
              "         0,  5,  6,  6,  0,  5,  5,  0,  0,  0,  0,  0,  5,  5,  5,  5,  9,  0,\n",
              "         0,  0,  0,  0,  5,  0,  7,  0,  0,  7,  0,  7,  0,  0,  0,  5,  0,  9,\n",
              "         0,  7,  5,  0,  0,  0,  5,  0,  0,  0,  0,  6,  0,  0,  0,  9,  9,  9,\n",
              "         9,  9,  9,  9,  0,  0,  5,  6,  6,  9,  5,  0,  0,  0,  0,  7,  5,  0,\n",
              "         0,  0,  7,  0,  0,  7,  0,  5,  0,  0,  0,  0,  0,  0,  0,  5,  6,  6,\n",
              "         0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  5,  0,\n",
              "         0,  0,  9,  9,  9,  9,  9,  9,  9,  0,  0,  0,  0,  7,  5,  7,  7,  7,\n",
              "         0,  5,  0,  0,  6,  6,  9,  0,  0,  0,  7,  5,  5,  0,  0,  0,  0,  0,\n",
              "         9,  0,  0,  0,  5,  6,  9,  0], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Oahd4cP90ms"
      },
      "source": [
        "## Classifier Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8zokKeJ-RGI"
      },
      "source": [
        "### Definition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class JointIntentAndSlotFillingModel(nn.Module):\n",
        "    def __init__(self, slot_num_labels, model_name=model_name, dropout_prob=0.1):\n",
        "        super(JointIntentAndSlotFillingModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.slot_classifier = nn.Linear(self.bert.config.hidden_size, slot_num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        slot_logits = self.slot_classifier(sequence_output)\n",
        "\n",
        "        return slot_logits"
      ],
      "metadata": {
        "id": "ONebOlWUixCm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMpHQUuwVT84"
      },
      "source": [
        "joint_model = JointIntentAndSlotFillingModel(slot_num_labels=len(slot_map))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaI_qVxI-Xo4"
      },
      "source": [
        "### Hyperparams, Optimizer and Loss function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchmetrics"
      ],
      "metadata": {
        "id": "ltYAG5qpkOtM",
        "outputId": "cc69596b-cf71-44a6-854d-75463b45de61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZeZf3JVT84"
      },
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "# Configure the optimizer\n",
        "optimizer = AdamW(joint_model.parameters(), lr=3e-5, eps=1e-08)\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Define the metric for multiclass classification\n",
        "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=len(slot_map), average='macro')\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogJCgyMG-o4A"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input IDs type: {type(encoded_texts['input_ids'])}, shape: {encoded_texts['input_ids'].shape}\")\n",
        "print(f\"Token Type IDs type: {type(encoded_texts['token_type_ids'])}, shape: {encoded_texts['token_type_ids'].shape}\")\n",
        "print(f\"Attention Mask type: {type(encoded_texts['attention_mask'])}, shape: {encoded_texts['attention_mask'].shape}\")\n",
        "print(f\"Slots type: {type(encoded_slots)}, shape: {encoded_slots.shape}\")\n",
        "\n",
        "# Ensure all tensors have the same size in the first dimension\n",
        "assert encoded_texts['input_ids'].shape[0] == encoded_texts['token_type_ids'].shape[0] == encoded_texts['attention_mask'].shape[0] == encoded_slots.shape[0], \"Mismatch in the first dimension of the tensors\"\n"
      ],
      "metadata": {
        "id": "JJX7bJJauShe",
        "outputId": "e98d62d6-e9f3-44e4-d444-01e9879cfb3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs type: <class 'torch.Tensor'>, shape: torch.Size([100, 512])\n",
            "Token Type IDs type: <class 'torch.Tensor'>, shape: torch.Size([100, 512])\n",
            "Attention Mask type: <class 'torch.Tensor'>, shape: torch.Size([100, 512])\n",
            "Slots type: <class 'torch.Tensor'>, shape: torch.Size([100, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "\n",
        "# Convert the encoded texts and slots to a TensorDataset\n",
        "dataset = TensorDataset(\n",
        "    encoded_texts[\"input_ids\"],\n",
        "    encoded_texts[\"token_type_ids\"],\n",
        "    encoded_texts[\"attention_mask\"],\n",
        "    encoded_slots\n",
        ")\n",
        "\n",
        "# Create a DataLoader to handle batching and shuffling\n",
        "data_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Move the model to the appropriate device (GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "joint_model.to(device)\n",
        "\n",
        "# Training loop\n",
        "joint_model.train()  # Set the model to training mode\n",
        "for epoch in range(2):\n",
        "    for batch in data_loader:\n",
        "        # Unpack the batch and move to the same device as the model\n",
        "        input_ids, token_type_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        # Zero the gradients before running the forward pass.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        labels = labels.long()\n",
        "\n",
        "        # Forward pass: compute the output of the model by passing in the batch\n",
        "        outputs = joint_model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "\n",
        "        # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform a single optimization step to update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute the accuracy\n",
        "        # Note: You'll need to modify the accuracy calculation to match your scenario\n",
        "        # For example, you may need to mask out certain tokens when calculating accuracy\n",
        "        predictions = outputs.argmax(dim=2)  # Assuming labels are at the token level\n",
        "        correct_predictions = predictions.eq(labels)\n",
        "        accuracy = correct_predictions.sum().item() / correct_predictions.numel()\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}\")\n",
        "\n",
        "# After training, you'll typically want to save the model's state\n",
        "torch.save(joint_model.state_dict(), 'joint_intent_slot_model.pth')\n"
      ],
      "metadata": {
        "id": "-YBxCTUktPe7",
        "outputId": "2cce17cf-93c2-4ee5-9b2e-6ac0ccb95b53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.45151251554489136, Accuracy: 0.87158203125\n",
            "Epoch: 1, Loss: 0.6168619394302368, Accuracy: 0.81689453125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOSkQ6mZ-sMg"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZqMiC_gZM5s"
      },
      "source": [
        "import torch\n",
        "\n",
        "def nlu(text, tokenizer, model, slot_names):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    # Ensure model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize input text and convert to PyTorch tensors\n",
        "    encoded_input = tokenizer.encode_plus(\n",
        "        text,\n",
        "        return_tensors=\"pt\",  # Return PyTorch tensors\n",
        "        add_special_tokens=True  # Add '[CLS]' and '[SEP]'\n",
        "    )\n",
        "\n",
        "    # Move tensors to the same device as the model\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Forward pass, disable gradient calculations\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Assuming the first output of the model is slot logits\n",
        "    slot_logits = outputs[0]\n",
        "\n",
        "    # Get the predicted slot IDs\n",
        "    slot_ids = slot_logits.argmax(dim=-1).squeeze(0).cpu().numpy()\n",
        "\n",
        "    info = {\"slots\": {}}\n",
        "    out_dict = {}\n",
        "\n",
        "    # Collect unique predicted slot names (excluding the padding slot)\n",
        "    predicted_slots = set([slot_names[s] for s in slot_ids if s != 0])\n",
        "    for ps in predicted_slots:\n",
        "        out_dict[ps] = []\n",
        "\n",
        "    # Tokenize the text for token-level alignment\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    for token, slot_id in zip(tokens, slot_ids):\n",
        "        slot_name = slot_names[slot_id]\n",
        "        if slot_name == \"<PAD>\":\n",
        "            continue\n",
        "\n",
        "        collected_tokens = [token]\n",
        "        idx = tokens.index(token)\n",
        "\n",
        "        # Check if the token is a continuation of the previous one\n",
        "        if token.startswith(\"##\"):\n",
        "            # Merge with the previous token\n",
        "            collected_tokens.insert(0, tokens[idx - 1])\n",
        "\n",
        "        # Add the collected tokens to the slot\n",
        "        out_dict[slot_name].extend(collected_tokens)\n",
        "\n",
        "    # Convert tokens to strings for each slot\n",
        "    for slot_name in out_dict:\n",
        "        tokens = out_dict[slot_name]\n",
        "        slot_value = tokenizer.convert_tokens_to_string(tokens)\n",
        "        info[\"slots\"][slot_name] = slot_value.strip()\n",
        "\n",
        "    return info\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzuZBVpu_K9Q",
        "outputId": "9f8560e8-a593-40a0-8ca2-d367865e3683"
      },
      "source": [
        "nlu(\"On April 5  2010  an employee and a coworker of a utility contractor were  involved with the replacement of natural gas line risers at single family  homes. A 3-ft deep hole was hand dug  approximately 18-in. in diameter  to  access the main 1-in. gas line. A footage squeeze tool was clamped onto the  1-in. main gas line and the old riser assembly was removed. During the process  of installing the new riser  the clamp was removed causing the flow of natural  gas to enter the excavated hole. The employee was found by the coworker face  down in the hole overcome by the gas. The employee was killed.\", tokenizer, joint_model, slot_names)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'slots': {'EVENT': 'employee main 1 old process new the c flow excavated coworker face hole gas',\n",
              "  'ACTIVITY': 'cow utility replacement of natural rise at installing natural',\n",
              "  'WHO': 'and cowororker of'}}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWCPwzLP_rQc"
      },
      "source": [
        "## Usage of llama2\n",
        "\n",
        "This section use llama2 model to do prompt engineering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "folder_path = '/content/model'  # Replace with your folder path\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_path):\n",
        "    try:\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Folder '{folder_path}' and all its contents have been deleted.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_path}' does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isV7ZqQz5JVk",
        "outputId": "d3921f91-86fa-44c2-9390-7e14ebdf8f71"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/model' does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain einops accelerate transformers bitsandbytes scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aiywLpl1nnc",
        "outputId": "1587aa69-b69e-445e-f3c6-058b4c8f8d08"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.71-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.5.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: bitsandbytes, mypy-extensions, marshmallow, jsonpointer, einops, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, accelerate, langchain-community, langchain\n",
            "Successfully installed accelerate-0.25.0 bitsandbytes-0.41.3.post2 dataclasses-json-0.6.3 einops-0.7.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.350 langchain-community-0.0.3 langchain-core-0.1.1 langsmith-0.0.71 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wd4JgAu10f3",
        "outputId": "64bf1470-28e5-4c9a-dc92-31af343e1bc8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import transformer classes for generaiton\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
        "# Import torch for datatype attributes\n",
        "import torch"
      ],
      "metadata": {
        "id": "-v2fBhAs1Vgn"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variable to hold llama2 weights naming\n",
        "name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "# Set auth token variable from hugging face\n",
        "auth_token = \"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\""
      ],
      "metadata": {
        "id": "DBrCZ8yt02aM"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(name,\n",
        "    cache_dir='./model/', use_auth_token=auth_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201,
          "referenced_widgets": [
            "5d895ee3c2f24cf093ed8e324d8a0906",
            "eb52cc7134984a82bbe2c4956b8b2496",
            "e59d3991235d49da9435f3d56c2fd4ed",
            "7357b9d5f69e4127811ca68a8932d96b",
            "0454fdc8314d43a09c8fe4928993139a",
            "84aa96d9f4b84755a7881a1a5e73117d",
            "1a07031b0cff47abb9c5aad9ada11eed",
            "9799f2695b4c4b489df41184c7320d76",
            "c89a80f0ff4842fca703df8f4db9b16f",
            "e3867796c37d48109ec500527df5418a",
            "649f96a1cd364ee9bd07d0b2ddff725f",
            "ed893a4c1733449eb0e3c3fdc0dad3ee",
            "cd31507af0a641639da8c303b1137575",
            "a007799b05234a4d87562f96ac68f0b9",
            "f03b677ec46240af9e7eb3c46db805fb",
            "2b831ecdf281410b8045c41ca73e2283",
            "2266674c45d942329e9f3456c2a85f4b",
            "44478ec9d27444aaa2906f898a3b64e5",
            "41c37c2e5f33472c98b4f39df28341a2",
            "4c88e144ea914859a192dfe2c1539b0d",
            "636bd35486bc4906881bf1776283e2e8",
            "983f4746819b4caaa85f64429d0b7c10",
            "77494927d0074f97af78ad776cd06bd4",
            "b6005517db33438d9ee6d9459c42e48b",
            "46ed8682c81d4d829581086ccaa6c82b",
            "e5bcd20650524552a211eae0f4f9bf4c",
            "64a48eebf45d480191115426ddfbab7b",
            "5ee3a5cee13245259b35a1d2914ed4c8",
            "37df1f4cc20848c1b5405075c7fe1cba",
            "cb61438f15194325878f42babd7278e2",
            "2cfdc8235aca4ba9898dd5d55363c18c",
            "cc8cfe1b42f748a78254e56d7d3434c2",
            "694f871c818843aca5b180fc0265a56c",
            "1c0891b952744a9b97819b45ea0374ae",
            "e118eb0a973e4f1aa1c3766944a754ec",
            "4f03a93e3fa446159dda4ac863bc87f3",
            "96f564ea5b0c4e6bb144645e7decc5a5",
            "6119f5f4d22f4095b00e31937d45f3b5",
            "22d1e67ac2f245e1b7fd213e4ba7fbb2",
            "10b84e76b0aa4a7aa999c31b176414c3",
            "c734f081e9ab472b9fd1caa8d6f60caa",
            "1551553bde5840f39eba4168785a0305",
            "656e046ec8c34af4b286333a22879da3",
            "5e2178758b3347969d32f98b9758e087"
          ]
        },
        "id": "cSDnix0i1GDk",
        "outputId": "08cc1c2c-b76e-4cef-b44b-1a443e53cb0f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d895ee3c2f24cf093ed8e324d8a0906"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed893a4c1733449eb0e3c3fdc0dad3ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77494927d0074f97af78ad776cd06bd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c0891b952744a9b97819b45ea0374ae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-VBC0MwLB-77"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = AutoModelForCausalLM.from_pretrained(name,\n",
        "    cache_dir='./model/', use_auth_token=auth_token, torch_dtype=torch.float16,\n",
        "    rope_scaling={\"type\": \"dynamic\", \"factor\": 2}, load_in_8bit=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648,
          "referenced_widgets": [
            "5e724ce593e2492abff6df0f6d81248c",
            "e0ee3364041d4495b0afd3e3a7757cb8",
            "6d28116701b54c3d94a170eb8f639747",
            "8d8240d71cc1418bbaa8c88fa0f5ccd1",
            "25767f593cb0494592d07bd83872ba41",
            "2629265df0b84e77b16533412e6e0315",
            "72c7e4bf55a14bdc81462486db503f06",
            "8528cf1d5d7c472fb1e0ff92608b910b",
            "c3608d87e95449cb908abe1a36ae6c30",
            "cfdeeaf4c4d4467091b88efd0ad316f9",
            "a8a92504bf714e7f9bb4d80802e2ac85"
          ]
        },
        "id": "Oe7fnOZm1Rp-",
        "outputId": "2e2f0b50-70e2-4987-9bb9-0284935e5beb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e724ce593e2492abff6df0f6d81248c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-44fd5f84e651>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(name,\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./model/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     rope_scaling={\"type\": \"dynamic\", \"factor\": 2}, load_in_8bit=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_in_8bit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   2715\u001b[0m                     \u001b[0;34m\"Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m                     \u001b[0;34m\" bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a prompt\n",
        "prompt = \"### User:What is the fastest car in  \\\n",
        "          the world and how much does it cost? \\\n",
        "          ### Assistant:\"\n",
        "# Pass the prompt to the tokenizer\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "# Setup the text streamer\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "# Actually run the thing\n",
        "output = model.generate(**inputs, streamer=streamer,\n",
        "                        use_cache=True, max_new_tokens=float('inf'))"
      ],
      "metadata": {
        "id": "M2rh5IGa6o3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on dataset exemple."
      ],
      "metadata": {
        "id": "URqOFj-Q7ARW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exemple = new_examples[0]\n",
        "answers = new_examples[0][\"arguments\"]"
      ],
      "metadata": {
        "id": "onGJBMiMHALc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = train_data[1][\"text\"]\n",
        "context_expected_response = train_data[1][\"arguments\"]\n",
        "\n",
        "\n",
        "\n",
        "new_question = exemple[\"text\"]\n",
        "\n",
        "# Setup a prompt\n",
        "prompt = f\"###  \\\n",
        "          Q: Can you extract informations from this description of an incident ? You dont need to give the context in your answer.: {context}\\\n",
        "          A: {context_expected_response} \\\n",
        "          Q: Can you extract informations from this description of an incident ? You dont need to give the context in your answer.: {new_question}: \\\n",
        "          A: \"\n",
        "# Pass the prompt to the tokenizer\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "# Setup the text streamer\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "# Actually run the thing\n",
        "output = model.generate(**inputs, streamer=streamer,\n",
        "                        use_cache=True, max_new_tokens=float('inf'))"
      ],
      "metadata": {
        "id": "4Ng-nx5F7N8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating"
      ],
      "metadata": {
        "id": "Gi1gf0jxBHlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Mettre en minuscule et retirer la ponctuation, des déterminants and les espaces.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    \"\"\"Normalise les 2 textes, trouve ce qu'il y a en comment et estime précision, rappel et F1.\"\"\"\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if len(ground_truth_tokens) == 0 or len(prediction_tokens) == 0:\n",
        "        return int(ground_truth_tokens == prediction_tokens)\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    \"\"\"Vérifie si les 2 textes sont quasi-identiques.\"\"\"\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
        "    \"\"\"La fonction princiaple. Important de noter que ground_truths est une liste\n",
        "       parce qu'il peut y avoir plusieurs réponses possibles.\"\"\"\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "def evaluate_demo(prediction, ground_truths):\n",
        "    \"\"\"Fonction utilitaire pour illuster l'utilisation de metric_max_over_ground_truths.\n",
        "       Vous pouvez créer votre propre fonction selon vos besoins. \"\"\"\n",
        "    exact_match = metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\n",
        "    f1_value = metric_max_over_ground_truths(f1_score, prediction, ground_truths)\n",
        "\n",
        "    # Log the prediction and the ground truths\n",
        "    print(\"Prediction:\", prediction)\n",
        "\n",
        "    # Log the evaluation metrics\n",
        "    print('Exact match:', exact_match, '\\nF1:', f1_value)\n",
        "\n",
        "# def evaluate_multiple(predictions, ground_truths):\n",
        "#     total_score = 0\n",
        "#     for prediction, ground_truth in zip(predictions, ground_truths):\n",
        "#         total_score += evaluate_demo(prediction, ground_truth)\n",
        "\n",
        "#     average_score = total_score / len(predictions)\n",
        "#     return average_score\n"
      ],
      "metadata": {
        "id": "54REIPyLBFD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Decode the output to json\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True).split(\"A: \")[-1].strip().replace(\"'\", '\"')\n",
        "output_json = json.loads(decoded_output)"
      ],
      "metadata": {
        "id": "MXERC0vDCEiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in output_json.items():\n",
        "  for prediction in v:\n",
        "        evaluate_demo(prediction, answers[k])\n",
        "  print(answers[k])"
      ],
      "metadata": {
        "id": "D-F3MZRAGwb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}